{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**    \n",
    "- Model Training Code    \n",
    "  - Current image data    \n",
    "  - Image data    \n",
    "  - Final dataset    \n",
    "  - Steps for training the model    \n",
    "  - Data Cleaning & Preprocessing    \n",
    "    - Load the data    \n",
    "    - Preprocess the data    \n",
    "    - Data Augmentation    \n",
    "    - Data Normalization    \n",
    "    - Data Splitting    \n",
    "  - Model Building    \n",
    "    - Model Architecture    \n",
    "    - Model Compilation    \n",
    "  - Model Training    \n",
    "    - Model Training    \n",
    "  - Model Evaluation    \n",
    "    - Model Evaluation    \n",
    "    - Model Saving    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=false\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will train a model based on image data using tensorflow and yolo. The model will be trained on the dataset of images of the 4 different colors 2-d surfaces (Red, Green, Blue, Yellow) and will be used to predict the color of the surface in the image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current image data\n",
    "Currently, I have a dataset of 4 cubes, each broken down to categories:\n",
    "1. color\n",
    "2. drawing\n",
    "\n",
    "We are going to utilize only the color data for now. The color data is broken down into 4 categories:\n",
    "1. Red\n",
    "2. Green\n",
    "3. Blue\n",
    "4. Yellow\n",
    "\n",
    "The dataset is in the form of images of the 4 colors. The images are taken from different angles and lighting conditions to make the model robust to different conditions.\n",
    "\n",
    "After running this trial model, we will use the real dataset of cubes to train the model to detect real cubes.\n",
    "\n",
    ", we will use a pre-trained model and fine-tune it on the dataset of the 4 colors. We will use the YOLO model for this purpose.\n",
    "\n",
    "## Image data\n",
    "\n",
    "In addition to the base dataset, we will also use a dataset of real images of cubes. I've taken open source datasets of different cubes, such as rubik's cubes, and used them as the real dataset. We will use this dataset to train the model to detect real cubes.\n",
    "\n",
    "## Final dataset\n",
    "\n",
    "As we complete and test the model based off the\n",
    "base dataset and the real dataset, we will combine the two datasets to create the final dataset.\n",
    ", we will combine the base dataset and the real dataset (from accumulating pictures of the camera on the robotic arm) to create the final dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BOX_0017 Small.jpeg](<attachment:BOX_0017 Small.jpeg>) ![BOX_0018 Small.jpeg](<attachment:BOX_0018 Small.jpeg>) ![BOX_0020 Small.jpeg](<attachment:BOX_0020 Small.jpeg>) ![BOX_0021 Small.jpeg](<attachment:BOX_0021 Small.jpeg>) ![BOX_0304 Small.jpeg](<attachment:BOX_0304 Small.jpeg>) ![BOX_0310 Small.jpeg](<attachment:BOX_0310 Small.jpeg>) ![BOX_0311 Small.jpeg](<attachment:BOX_0311 Small.jpeg>) ![BOX_0312 Small.jpeg](<attachment:BOX_0312 Small.jpeg>) ![BOX_0314 Small.jpeg](<attachment:BOX_0314 Small.jpeg>) ![BOX_0315 Small.jpeg](<attachment:BOX_0315 Small.jpeg>) ![BOX_0316 Small.jpeg](<attachment:BOX_0316 Small.jpeg>) ![BOX_0317 Small.jpeg](<attachment:BOX_0317 Small.jpeg>) ![BOX_0318 Small.jpeg](<attachment:BOX_0318 Small.jpeg>) ![BOX_0319 Small.jpeg](<attachment:BOX_0319 Small.jpeg>) ![BOX_0320 Small.jpeg](<attachment:BOX_0320 Small.jpeg>) ![BOX_0321 Small.jpeg](<attachment:BOX_0321 Small.jpeg>) ![BOX_0322 Small.jpeg](<attachment:BOX_0322 Small.jpeg>) ![BOX_0323 Small.jpeg](<attachment:BOX_0323 Small.jpeg>) ![BOX_0324 Small.jpeg](<attachment:BOX_0324 Small.jpeg>) ![BOX_0325 Small.jpeg](<attachment:BOX_0325 Small.jpeg>) ![BOX_0326 Small.jpeg](<attachment:BOX_0326 Small.jpeg>) ![BOX_0327 Small.jpeg](<attachment:BOX_0327 Small.jpeg>) ![BOX_0328 Small.jpeg](<attachment:BOX_0328 Small.jpeg>) ![BOX_0329 Small.jpeg](<attachment:BOX_0329 Small.jpeg>) ![BOX_0330 Small.jpeg](<attachment:BOX_0330 Small.jpeg>) ![BOX_0331 Small.jpeg](<attachment:BOX_0331 Small.jpeg>) ![BOX_0332 Small.jpeg](<attachment:BOX_0332 Small.jpeg>) ![BOX_0333 Small.jpeg](<attachment:BOX_0333 Small.jpeg>) ![BOX_0334 Small.jpeg](<attachment:BOX_0334 Small.jpeg>) ![BOX_0335 Small.jpeg](<attachment:BOX_0335 Small.jpeg>) ![BOX_0336 Small.jpeg](<attachment:BOX_0336 Small.jpeg>) ![BOX_0337 Small.jpeg](<attachment:BOX_0337 Small.jpeg>) ![BOX_0338 Small.jpeg](<attachment:BOX_0338 Small.jpeg>) ![BOX_0339 Small.jpeg](<attachment:BOX_0339 Small.jpeg>) ![BOX_0340 Small.jpeg](<attachment:BOX_0340 Small.jpeg>) ![BOX_0341 Small.jpeg](<attachment:BOX_0341 Small.jpeg>) ![BOX_0342 Small.jpeg](<attachment:BOX_0342 Small.jpeg>) ![BOX_0343 Small.jpeg](<attachment:BOX_0343 Small.jpeg>) ![BOX_0344 Small.jpeg](<attachment:BOX_0344 Small.jpeg>) ![BOX_0345 Small.jpeg](<attachment:BOX_0345 Small.jpeg>) ![BOX_0346 Small.jpeg](<attachment:BOX_0346 Small.jpeg>) ![BOX_0347 Small.jpeg](<attachment:BOX_0347 Small.jpeg>) ![BOX_0348 Small.jpeg](<attachment:BOX_0348 Small.jpeg>) ![BOX_0349 Small.jpeg](<attachment:BOX_0349 Small.jpeg>) ![BOX_0350 Small.jpeg](<attachment:BOX_0350 Small.jpeg>) ![BOX_0351 Small.jpeg](<attachment:BOX_0351 Small.jpeg>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for training the model\n",
    "1. Data Cleaning & Preprocessing\n",
    "    1. Load the data\n",
    "    2. Preprocess the data\n",
    "    3. Data Augmentation\n",
    "    4. Data Normalization\n",
    "    5. Data Splitting\n",
    "2. Model Building\n",
    "    1. Model Architecture\n",
    "    2. Model Compilation\n",
    "3. Model Training\n",
    "    1. Model Training\n",
    "4. Model Evaluation\n",
    "    1. Model Evaluation\n",
    "    2. Model Saving\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Data Cleaning & Preprocessing\n",
    "The data is cleaned and preprocessed before training the model. The data is loaded, preprocessed, augmented, normalized, and split into training and validation sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Load the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Preprocess the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Splitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  \n",
    "Model Building - YOLO \n",
    "We will use the YOLO model for training the model. The YOLO model is a state-of-the-art object detection model that is used for detecting objects in images. We will use a pre-trained YOLO model and fine-tune it on the dataset of the 4 colors. This en\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model Architecture\n",
    "\n",
    "```python\n",
    "# Load the pre-trained YOLO model\n",
    "yolo_model = tf.keras.applications.YOLOv3(weights='yolov3.h5')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model Compilation\n",
    "\n",
    "```python\n",
    "# Compile the model\n",
    "yolo_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model Training\n",
    "\n",
    "The model is trained on the training data. The model is trained using the fit method of the model object.\n",
    "\n",
    "```python\n",
    "# Train the model\n",
    "yolo_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "```\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "The model is evaluated on the validation data. The model is evaluated using the evaluate method of the model object.\n",
    "\n",
    "```python\n",
    "# Evaluate the model\n",
    "yolo_model.evaluate(X_val, y_val)\n",
    "```\n",
    "\n",
    "### Model Evaluation\n",
    "\n",
    "### Model Saving\n",
    "\n",
    "```python\n",
    "# Save the model\n",
    "yolo_model.save('yolo_model.h5')\n",
    "```\n",
    "\n",
    "## Model Building\n",
    "### Model Architecture\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Model Compilation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model Training\n",
    "\n",
    "### Model Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model Evaluation\n",
    "\n",
    "### Model Evaluation\n",
    "\n",
    "### Model Saving\n",
    "\n",
    "The data is loaded from the dataset of images of the classes of fruits. The data is loaded using the `load_data` function from the `data_loader.py` file. The data is loaded in the form of a dictionary with the keys as the class names and the values as the images of the respective classes.\n",
    "\n",
    "```python\n",
    "import data_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
